# Sample configuration for a standalone Kafka Connect worker that uses Avro serialization and
# integrates the the Schema Registry. This sample configuration assumes a local installation of
# Confluent Platform with all services running on their default ports.

# Bootstrap Kafka servers. If multiple servers are specified, they should be comma-separated.
bootstrap.servers=broker:29092

# The converters specify the format of data in Kafka and how to translate it into Connect data.
# Every Connect user will need to configure these based on the format they want their data in
# when loaded from or stored into Kafka
key.converter=io.confluent.connect.avro.AvroConverter
key.converter.schema.registry.url=http://schema-registry:8081
value.converter=io.confluent.connect.avro.AvroConverter
value.converter.schema.registry.url=http://schema-registry:8081
value.converter.schemas.enable = true

# In standalone mode, the connector properties are usually set in the config file rather than using the defaults defined
# in the docker compose service. The listener port is also set in the config file, rather than handled at the service level.
plugin.path=/usr/share/java,/usr/share/confluent-hub-components,/data/connect-jars
listeners=http://:8084

# Local storage file for offset data
offset.storage.file.filename=/tmp/connect.offsets